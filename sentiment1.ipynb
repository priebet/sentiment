{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priebet/sentiment/blob/master/sentiment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4z8GjZ9Lv7T",
        "colab_type": "text"
      },
      "source": [
        "# Twitter-Sentimentanalyse Teil 1\n",
        "## Vorbereitung des Sentiment140 Trainings-Datensatzes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P3TqltkLqwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount Google Drive for easy and fast read/write access to data folder \n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#datapath = \"/content/drive/My Drive/Colab Notebooks/data/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wypdv6lqGayG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For demonstration purposes, pull data from webserver instead\n",
        "datapath = \"http://priebe.onl/data/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjSMhJiV9h_Q",
        "colab_type": "code",
        "outputId": "45522e6a-0acf-4ae2-c0ec-114e6656b8a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "import pandas as pd  \n",
        "\n",
        "# Load Sentiment140 training data set, choose only relevant columns and encode \n",
        "# positive sentiment as 1 instead of 4\n",
        "df = pd.read_csv(datapath+\"training.csv\",header=None,\n",
        "                 usecols=[0,5],names=['sentiment','text'],encoding='latin1')\n",
        "df['sentiment'] = df['sentiment'].map({0: 0, 4: 1})\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                               text\n",
              "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  is upset that he can't update his Facebook by ...\n",
              "2          0  @Kenichan I dived many times for the ball. Man...\n",
              "3          0    my whole body feels itchy and like its on fire \n",
              "4          0  @nationwideclass no, it's not behaving at all...."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jkZpgAf9NQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This code is 1:1 as presented by Ricky Kim, please refer to:\n",
        "# https://towardsdatascience.com/another-twitter-sentiment-analysis-bb5b01ebad90\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tok = WordPunctTokenizer()\n",
        "\n",
        "pat1 = r'@[A-Za-z0-9_]+'\n",
        "pat2 = r'https?://[^ ]+'\n",
        "combined_pat = r'|'.join((pat1, pat2))\n",
        "www_pat = r'www.[^ ]+'\n",
        "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
        "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
        "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
        "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
        "                \"mustn't\":\"must not\"}\n",
        "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
        "\n",
        "def tweet_cleaner_updated(text):\n",
        "    soup = BeautifulSoup(text, 'lxml')\n",
        "    souped = soup.get_text()\n",
        "    try:\n",
        "        bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
        "    except:\n",
        "        bom_removed = souped\n",
        "    stripped = re.sub(combined_pat, '', bom_removed)\n",
        "    stripped = re.sub(www_pat, '', stripped)\n",
        "    lower_case = stripped.lower()\n",
        "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)\n",
        "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1]\n",
        "    return (\" \".join(words)).strip()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdpYh2NP-FRR",
        "colab_type": "code",
        "outputId": "26bbaf31-92ae-4dc0-86fc-9de6f7ec1c9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "%%time\n",
        "print(\"Cleaning the tweets...\\n\")\n",
        "clean_tweet_texts = []\n",
        "for i in range(0,len(df)):\n",
        "    if( (i+1)%100000 == 0 ):\n",
        "        print(\"Tweets %d of %d has been processed\" % (i+1, len(df)))                                                               \n",
        "    clean_tweet_texts.append(tweet_cleaner_updated(df['text'][i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cleaning the tweets...\n",
            "\n",
            "Tweets 100000 of 1600000 has been processed\n",
            "Tweets 200000 of 1600000 has been processed\n",
            "Tweets 300000 of 1600000 has been processed\n",
            "Tweets 400000 of 1600000 has been processed\n",
            "Tweets 500000 of 1600000 has been processed\n",
            "Tweets 600000 of 1600000 has been processed\n",
            "Tweets 700000 of 1600000 has been processed\n",
            "Tweets 800000 of 1600000 has been processed\n",
            "Tweets 900000 of 1600000 has been processed\n",
            "Tweets 1000000 of 1600000 has been processed\n",
            "Tweets 1100000 of 1600000 has been processed\n",
            "Tweets 1200000 of 1600000 has been processed\n",
            "Tweets 1300000 of 1600000 has been processed\n",
            "Tweets 1400000 of 1600000 has been processed\n",
            "Tweets 1500000 of 1600000 has been processed\n",
            "Tweets 1600000 of 1600000 has been processed\n",
            "CPU times: user 7min 44s, sys: 25.1 s, total: 8min 9s\n",
            "Wall time: 8min 10s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S8tgNnO-4SD",
        "colab_type": "code",
        "outputId": "c8a7c578-8170-4a5f-d788-e0313154b532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "clean_df = pd.DataFrame(clean_tweet_texts,columns=['text'])\n",
        "clean_df['sentiment'] = df['sentiment']\n",
        "\n",
        "# Remove rows with empty text (after cleaning) and reset index\n",
        "clean_df = clean_df.loc[clean_df['text'] != \"\"]\n",
        "clean_df.reset_index(drop=True,inplace=True)\n",
        "\n",
        "clean_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>awww that bummer you shoulda got david carr of...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is upset that he can not update his facebook b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dived many times for the ball managed to save ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>no it not behaving at all mad why am here beca...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  sentiment\n",
              "0  awww that bummer you shoulda got david carr of...          0\n",
              "1  is upset that he can not update his facebook b...          0\n",
              "2  dived many times for the ball managed to save ...          0\n",
              "3     my whole body feels itchy and like its on fire          0\n",
              "4  no it not behaving at all mad why am here beca...          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geo_NMobUWTK",
        "colab_type": "code",
        "outputId": "2b8dd699-9c37-4f9e-e6f8-ec66369c0556",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "# Store cleaned training data as CSV file, does not apply when using webserver\n",
        "# as storage location\n",
        "#clean_df.to_csv(datapath+'training_cleaned.csv',encoding='utf-8',index=False)\n",
        "clean_df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1596041 entries, 0 to 1596040\n",
            "Data columns (total 2 columns):\n",
            "text         1596041 non-null object\n",
            "sentiment    1596041 non-null int64\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 24.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}